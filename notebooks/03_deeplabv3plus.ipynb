{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "644dc67a",
   "metadata": {},
   "source": [
    "# DeepLabV3+ for Cell Segmentation\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MateiGoidan/CellSeg/blob/main/notebooks/03_deeplabv3plus.ipynb)\n",
    "\n",
    "---\n",
    "## 1. Setup\n",
    "Import dependencies and configure environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XTrTsIpFeiJH",
    "outputId": "095cf32c-813e-41a7-e014-06e649c299ed"
   },
   "outputs": [],
   "source": [
    "# @title Conectare la drive\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ydxHM66Y96az"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZ2HcZx83PbS"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "JnD9Iuiqy1mH"
   },
   "outputs": [],
   "source": [
    "# @title Path-uri\n",
    "\n",
    "train_img_path = \"/content/drive/MyDrive/Facultate/Licenta/ds1/train/img/cls\"\n",
    "train_bin_mask_path = \"/content/drive/MyDrive/Facultate/Licenta/ds1/train/bin_mask/cls\"\n",
    "train_mult_mask_path = \"/content/drive/MyDrive/Facultate/Licenta/ds1/train/mult_mask/cls\"\n",
    "\n",
    "validation_img_path = \"/content/drive/MyDrive/Facultate/Licenta/ds1/validation/img/cls\"\n",
    "validation_bin_mask_path = \"/content/drive/MyDrive/Facultate/Licenta/ds1/validation/bin_mask/cls\"\n",
    "validation_mult_mask_path = \"/content/drive/MyDrive/Facultate/Licenta/ds1/validation/mult_mask/cls\"\n",
    "\n",
    "test_img_path = \"/content/drive/MyDrive/Facultate/Licenta/ds1/test/img/cls\"\n",
    "test_mask_path = \"/content/drive/MyDrive/Facultate/Licenta/ds1/test/mult_mask/cls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "mbczV5WIeIdN"
   },
   "outputs": [],
   "source": [
    "# @title Incarcam path-urile\n",
    "\n",
    "def load_paths(imd_dir, mask_dir):\n",
    "  image_paths = sorted([os.path.join(imd_dir, file_name) for file_name in os.listdir(imd_dir) if file_name.endswith(\".tif\")])\n",
    "  mask_paths = sorted([os.path.join(mask_dir, file_name) for file_name in os.listdir(mask_dir) if file_name.endswith(\".tif\")])\n",
    "  return image_paths, mask_paths\n",
    "\n",
    "train_img_paths, train_mask_paths = load_paths(train_img_path, train_mult_mask_path)\n",
    "\n",
    "validation_img_paths, validation_mask_paths = load_paths(validation_img_path, validation_mult_mask_path)\n",
    "\n",
    "test_imgs_paths, test_masks_paths = load_paths(test_img_path, test_mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CwAcTMnD3ilx"
   },
   "outputs": [],
   "source": [
    "# @title Augumentare data (Improved)\n",
    "\n",
    "def augment_data(image, mask):\n",
    "  # Convert to float for augmentations\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  mask = tf.cast(mask, tf.float32) # Keep mask as float for transformations\n",
    "\n",
    "  # Random flip orizontal (higher probability)\n",
    "  if tf.random.uniform(()) > 0.3: # Increased chance of flipping\n",
    "    image = tf.image.flip_left_right(image)\n",
    "    mask = tf.image.flip_left_right(mask)\n",
    "\n",
    "  # Random flip vertical (higher probability)\n",
    "  if tf.random.uniform(()) > 0.3: # Increased chance of flipping\n",
    "    image = tf.image.flip_up_down(image)\n",
    "    mask = tf.image.flip_up_down(mask)\n",
    "\n",
    "  # Random brightness (more range)\n",
    "  if tf.random.uniform(()) > 0.4:\n",
    "    image = tf.image.random_brightness(image, max_delta=0.3) # Increased max_delta\n",
    "\n",
    "  # Random contrast (more range)\n",
    "  if tf.random.uniform(()) > 0.4:\n",
    "    image = tf.image.random_contrast(image, lower=0.7, upper=1.3) # Increased range\n",
    "\n",
    "  # Random rotation (still 90-degree steps as per tf.image.rot90)\n",
    "  if tf.random.uniform(()) > 0.4:\n",
    "      angle = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)\n",
    "      image = tf.image.rot90(image, angle)\n",
    "      mask = tf.image.rot90(mask, angle)\n",
    "\n",
    "  # Random Gaussian Noise (only applied to the image)\n",
    "  if tf.random.uniform(()) > 0.5:\n",
    "      noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=0.1, dtype=tf.float32) # Experiment with stddev\n",
    "      image = image + noise\n",
    "      image = tf.clip_by_value(image, -1.0, 1.0) # Clip to maintain normalization range\n",
    "\n",
    "  return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kl4oDdz13oxJ"
   },
   "outputs": [],
   "source": [
    "# @title Preprocesare imagine + masca\n",
    "\n",
    "def load_tif_with_pil(path):\n",
    "  img = Image.open(path.numpy().decode('utf-8'))\n",
    "  img = img.convert('L') # Convertim la grayscale\n",
    "  img = np.array(img, dtype=np.float32)\n",
    "  return img\n",
    "\n",
    "def preprocess_mult(img_path, mask_path):\n",
    "  img = tf.py_function(load_tif_with_pil, [img_path], tf.float32)\n",
    "  img = tf.expand_dims(img, axis=-1)\n",
    "  img.set_shape([None, None, 1])\n",
    "  img = tf.image.resize(img, (256, 256))\n",
    "  img = (img / 255.0) * 2.0 - 1.0 # Normalizare in intervalul [-1, 1]\n",
    "\n",
    "  # Convertim grayscale -> RGB prin replicarea canalului\n",
    "  img = tf.tile(img, [1, 1, 3])\n",
    "  img.set_shape([256, 256, 3])\n",
    "\n",
    "  mask = tf.py_function(load_tif_with_pil, [mask_path], tf.float32)\n",
    "  mask = tf.expand_dims(mask, axis=-1)\n",
    "  mask.set_shape([None, None, 1])\n",
    "  mask = tf.image.resize(mask, (256, 256), method='nearest')\n",
    "  mask = tf.squeeze(mask, axis=-1)          # Scoatem dimensiunea suplimentară\n",
    "  mask = tf.cast(mask, tf.uint8)\n",
    "  mask = tf.one_hot(mask, depth=8)           # Convertim la one-hot (8 clase)\n",
    "  mask = tf.cast(mask, tf.float32)           # TensorFlow vrea float pentru loss\n",
    "\n",
    "  # Setam shape explicit ca in paper\n",
    "  # img.set_shape([256, 256, 1])\n",
    "  mask.set_shape([256, 256, 8])\n",
    "\n",
    "  return img, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Qhg1O4p3z6S",
    "outputId": "df0d601d-6794-46be-eef9-13a56d49040f"
   },
   "outputs": [],
   "source": [
    "# @title Creare Dataset\n",
    "\n",
    "def create_dataset(img_paths, mask_paths, batch_size=8, shuffle=True, augment=False):\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((img_paths, mask_paths))\n",
    "  dataset = dataset.map(preprocess_mult, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "  if shuffle:\n",
    "    dataset = dataset.shuffle(buffer_size=100)\n",
    "\n",
    "  if augment:\n",
    "    dataset = dataset.map(lambda img, mask: augment_data(img, mask), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "  dataset = dataset.batch(batch_size)\n",
    "  dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "  return dataset\n",
    "\n",
    "\n",
    "# Recreate the training dataset with augment=True\n",
    "train_dataset = create_dataset(train_img_paths, train_mask_paths, batch_size=8, augment=True)\n",
    "\n",
    "validation_dataset = create_dataset(validation_img_paths, validation_mask_paths, batch_size=8, shuffle=False, augment=False) # Augmentation only on train\n",
    "\n",
    "test_dataset = create_dataset(test_imgs_paths, test_masks_paths, batch_size=8, shuffle=False, augment=False) # Augmentation only on train\n",
    "\n",
    "print(\"\\nDatasets recreated with enhanced augmentation.\")\n",
    "print(train_dataset.cardinality().numpy())\n",
    "print(validation_dataset.cardinality().numpy())\n",
    "print(test_dataset.cardinality().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "id": "DQfsZAnzEBiv",
    "outputId": "2e6f1b10-5648-4f1d-d316-b88ca239b905"
   },
   "outputs": [],
   "source": [
    "# Încarcă imaginea grayscale\n",
    "def load_grayscale_image(path):\n",
    "  img = Image.open(path)\n",
    "  img = img.convert('L')                      # grayscale\n",
    "  img = np.array(img, dtype=np.float32)       # (H, W)\n",
    "  img = (img / 255.0) * 2.0 - 1.0              # normalize [-1, 1]\n",
    "  img = np.expand_dims(img, axis=-1)          # (H, W, 1)\n",
    "  return img\n",
    "\n",
    "# Transformare în RGB (replicare canal)\n",
    "def convert_grayscale_to_rgb(img):\n",
    "  return np.repeat(img, repeats=3, axis=-1)   # (H, W, 3)\n",
    "\n",
    "# Exemplu\n",
    "img_path = \"/content/drive/MyDrive/Facultate/Licenta/ds1/train/img/cls/0014.tif\"  # Înlocuiește cu calea reală\n",
    "img_gray = load_grayscale_image(img_path)\n",
    "img_rgb = convert_grayscale_to_rgb(img_gray)\n",
    "\n",
    "# Afișare\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow((img_gray.squeeze() + 1) / 2, cmap='gray')  # reconvertim la [0, 1]\n",
    "plt.title(\"Grayscale originală\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow((img_rgb + 1) / 2)  # RGB normalizat la [0, 1]\n",
    "plt.title(\"După replicare canal (RGB)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NB8T2eC1-MBY"
   },
   "source": [
    "# DeepLabV3+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_UZOyrwCfZse",
    "outputId": "13dca255-4488-4ba0-8199-349732f44861"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def get_image_paths_with_class(class_index, mask_paths):\n",
    "  selected_paths = []\n",
    "  for path in tqdm(mask_paths):\n",
    "    mask = Image.open(path).convert('L')\n",
    "    mask = np.array(mask)\n",
    "    if class_index in mask:\n",
    "      selected_paths.append(path)\n",
    "  return selected_paths\n",
    "\n",
    "# Ex: pentru clasa 1 (WBC/RBC)\n",
    "mask_paths_with_class_1 = get_image_paths_with_class(1, train_mask_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jvH6Gag9fv6u",
    "outputId": "e1751405-18aa-487c-ae2f-6142d9fa68b8"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Clasele ignorate\n",
    "target_classes = {1, 3, 4, 6, 7}\n",
    "\n",
    "# Funcție: returnează path-urile de imagine + mască unde apar aceste clase\n",
    "def get_subset_paths(img_paths, mask_paths, target_classes):\n",
    "  selected_img_paths = []\n",
    "  selected_mask_paths = []\n",
    "\n",
    "  for img_path, mask_path in tqdm(zip(img_paths, mask_paths), total=len(mask_paths)):\n",
    "    mask = Image.open(mask_path).convert('L')\n",
    "    mask_np = np.array(mask)\n",
    "    if any(cls in mask_np for cls in target_classes):\n",
    "      selected_img_paths.append(img_path)\n",
    "      selected_mask_paths.append(mask_path)\n",
    "\n",
    "  return selected_img_paths, selected_mask_paths\n",
    "\n",
    "# Apel:\n",
    "img_subset_paths, mask_subset_paths = get_subset_paths(train_img_paths, train_mask_paths, target_classes)\n",
    "\n",
    "# Dataset cu doar exemplele care conțin clasele ignorate\n",
    "finetune_dataset = create_dataset(\n",
    "  img_subset_paths,\n",
    "  mask_subset_paths,\n",
    "  batch_size=4,  # batch mic pentru fine-tuning\n",
    "  shuffle=True,\n",
    "  augment=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--9O0bTyPcbH"
   },
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
    "  y_true = tf.cast(y_true, tf.float32)\n",
    "  y_pred = tf.cast(y_pred, tf.float32)\n",
    "  intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "  union = tf.reduce_sum(y_true + y_pred, axis=[1, 2, 3])\n",
    "  dice = (2. * intersection + smooth) / (union + intersection + smooth) # Corrected denominator for Dice Coefficient\n",
    "  return tf.reduce_mean(dice)\n",
    "\n",
    "def dice_loss(y_true, y_pred, smooth=1e-6):\n",
    "  y_true = tf.cast(y_true, tf.float32)\n",
    "  y_pred = tf.cast(y_pred, tf.float32)\n",
    "  intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "  union = tf.reduce_sum(y_true + y_pred, axis=[1, 2, 3])\n",
    "  dice = (2. * intersection + smooth) / (union + smooth)\n",
    "  return  1 -tf.reduce_mean(dice)\n",
    "\n",
    "def combined_focal_dice(gamma=2.0, alpha=0.25):\n",
    "  def loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0 - 1e-7)\n",
    "\n",
    "    # Focal Loss\n",
    "    ce = -y_true * tf.math.log(y_pred)\n",
    "    weight = alpha * tf.math.pow(1 - y_pred, gamma)\n",
    "    focal = tf.reduce_sum(weight * ce, axis=-1)\n",
    "    focal = tf.reduce_mean(focal)\n",
    "\n",
    "    # Dice Loss\n",
    "    dice = dice_loss(y_true, y_pred)\n",
    "\n",
    "    return focal + dice\n",
    "  return loss\n",
    "\n",
    "def focal_loss(class_weights, gamma=2.0):\n",
    "  class_weights = tf.constant(class_weights, dtype=tf.float32)\n",
    "\n",
    "  def loss(y_true, y_pred):\n",
    "    y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "    cross_entropy = -y_true * tf.math.log(y_pred)\n",
    "    weight = class_weights * y_true\n",
    "    focal = tf.math.pow(1 - y_pred, gamma) * cross_entropy * weight\n",
    "    return tf.reduce_mean(tf.reduce_sum(focal, axis=-1))  # medie pe batch.\n",
    "  return loss\n",
    "\n",
    "def multiclass_dice_loss():\n",
    "  def loss(y_true, y_pred, smooth=1e-6):\n",
    "    y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1,2])\n",
    "    union = tf.reduce_sum(y_true + y_pred, axis=[1,2])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return 1 - tf.reduce_mean(dice)\n",
    "  return loss\n",
    "\n",
    "def combined_loss(class_weights, gamma=2.0, weight_dice=1.0):\n",
    "  focal_fn = focal_loss(class_weights, gamma)\n",
    "  dice_fn = multiclass_dice_loss()\n",
    "  def loss(y_true, y_pred):\n",
    "    return focal_fn(y_true, y_pred) + weight_dice * dice_fn(y_true, y_pred)\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sFTyT5WqY5cc",
    "outputId": "b462c341-a417-45c3-8b41-a2bda6e4a597"
   },
   "outputs": [],
   "source": [
    "total_pixels = sum([1697, 1056, 41, 550, 182, 26, 10, 3562])\n",
    "class_counts = np.array([3562, 1697, 1056, 41, 550, 182, 26, 10]) # Order matters!\n",
    "# Ensure the order of class counts corresponds to your class indices (0 to 7)\n",
    "\n",
    "num_classes = 8\n",
    "class_weights = total_pixels / (class_counts * num_classes)\n",
    "class_weights = class_weights / np.sum(class_weights) * num_classes # Normalize weights\n",
    "\n",
    "print(\"Calculated Class Weights:\", class_weights)\n",
    "\n",
    "# Modify your combined_focal_dice loss to incorporate weights\n",
    "def weighted_combined_focal_dice(class_weights, gamma=2.0, alpha=0.25):\n",
    "  def loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0 - 1e-7)\n",
    "\n",
    "    # Apply weights to y_true for loss calculation\n",
    "    y_true_weighted = y_true * class_weights\n",
    "\n",
    "    # Focal Loss (applied to weighted true)\n",
    "    ce = -y_true_weighted * tf.math.log(y_pred) # Use weighted true here\n",
    "    weight = alpha * tf.math.pow(1 - y_pred, gamma)\n",
    "    focal = tf.reduce_sum(weight * ce, axis=-1)\n",
    "    focal = tf.reduce_mean(focal)\n",
    "\n",
    "    # Dice Loss (standard Dice calculation is often sufficient)\n",
    "    # If you want to weight Dice, it's a bit more complex, focusing on weighted intersection and union\n",
    "    # For simplicity, let's use the standard Dice for now, as Focal Loss will help with rare classes.\n",
    "    dice = dice_loss(y_true, y_pred) # Standard Dice Loss\n",
    "\n",
    "    return focal + dice\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "73Ty10MW-PGe"
   },
   "outputs": [],
   "source": [
    "def DeepLabV3Plus(input_shape=(256, 256, 3), n_classes=8, l2_lambda=0.0001):\n",
    "  base_model = Xception(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "  # ASPP\n",
    "  x = base_model.output\n",
    "\n",
    "  # Image Pooling branch (b4)\n",
    "  b4 = layers.GlobalAveragePooling2D()(x)\n",
    "  b4 = layers.Reshape((1, 1, -1))(b4)\n",
    "  b4 = layers.Conv2D(256, 1, padding='same', use_bias=False,\n",
    "                     kernel_regularizer=regularizers.l2(l2_lambda))(b4) # Added regularization\n",
    "  b4 = layers.BatchNormalization()(b4)\n",
    "  b4 = layers.Activation('relu')(b4)\n",
    "  # Upsampling to match 'x' size before concatenation for ASPP\n",
    "  # Note: This upsampling is within the ASPP block, not for the final concatenation with skip connection.\n",
    "  # The shape of 'x' here is typically reduced from the initial input, e.g., 32x32.\n",
    "  # The b4 branch output needs to be upsampled to match this 'x' spatial dimension (e.g., 32x32).\n",
    "  # Let's use the shape of 'x' to determine the correct upsampling factor.\n",
    "  b4 = layers.UpSampling2D(size=(x.shape[1] // b4.shape[1], x.shape[2] // b4.shape[2]), interpolation='bilinear')(b4)\n",
    "\n",
    "\n",
    "  # 1x1 Convolution branch (b0) - Corrected initialization\n",
    "  b0 = layers.Conv2D(256, 1, padding='same', use_bias=False,\n",
    "                     kernel_regularizer=regularizers.l2(l2_lambda))(x) # Apply to 'x' first\n",
    "  b0 = layers.BatchNormalization()(b0)\n",
    "  b0 = layers.Activation('relu')(b0)\n",
    "\n",
    "  # Dilated Convolution branches (b1, b2, b3)\n",
    "  b1 = layers.Conv2D(256, 3, dilation_rate=6, padding='same', use_bias=False,\n",
    "                     kernel_regularizer=regularizers.l2(l2_lambda))(x) # Added regularization\n",
    "  b1 = layers.BatchNormalization()(b1)\n",
    "  b1 = layers.Activation('relu')(b1)\n",
    "\n",
    "  b2 = layers.Conv2D(256, 3, dilation_rate=12, padding='same', use_bias=False,\n",
    "                     kernel_regularizer=regularizers.l2(l2_lambda))(x) # Added regularization\n",
    "  b2 = layers.BatchNormalization()(b2)\n",
    "  b2 = layers.Activation('relu')(b2)\n",
    "\n",
    "  b3 = layers.Conv2D(256, 3, dilation_rate=18, padding='same', use_bias=False,\n",
    "                     kernel_regularizer=regularizers.l2(l2_lambda))(x) # Added regularization\n",
    "  b3 = layers.BatchNormalization()(b3)\n",
    "  b3 = layers.Activation('relu')(b3)\n",
    "\n",
    "  # Concatenate ASPP branches\n",
    "  x = layers.Concatenate()([b4, b0, b1, b2, b3])\n",
    "  x = layers.Conv2D(256, 1, padding='same', use_bias=False,\n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda))(x) # Added regularization\n",
    "  x = layers.BatchNormalization()(x)\n",
    "  x = layers.Activation('relu')(x)\n",
    "\n",
    "  # Upsampling the ASPP output to match the spatial dimensions of the low-level skip connection\n",
    "  # Based on the error, the target size is likely (63, 63) for the skip connection from Xception's block3.\n",
    "  # Let's check the actual output shape of the target layer.\n",
    "  # However, based on the structure, the intent was likely to upsample to a specific size\n",
    "  # like (64, 64) or the original input size / 4.\n",
    "  # Let's assume the target for concatenation is (64, 64) as indicated by the original code's comment\n",
    "  # about resizing skip1 to 64x64.\n",
    "  target_h, target_w = 64, 64\n",
    "  x = layers.UpSampling2D(size=(target_h // x.shape[1], target_w // x.shape[2]), interpolation='bilinear')(x)\n",
    "\n",
    "\n",
    "  # Skip connection from the lower level (block3_sepconv2_bn)\n",
    "  skip1 = base_model.get_layer(\"block3_sepconv2_bn\").output\n",
    "  skip1 = layers.Conv2D(48, 1, padding='same', use_bias=False,\n",
    "                        kernel_regularizer=regularizers.l2(l2_lambda))(skip1) # Added regularization\n",
    "  skip1 = layers.BatchNormalization()(skip1)\n",
    "  skip1 = layers.Activation('relu')(skip1)\n",
    "\n",
    "  # Explicitly resize the skip connection to the target size for concatenation\n",
    "  # This handles cases where the base model output isn't exactly the desired size (e.g., 63x63 instead of 64x64)\n",
    "  skip1 = layers.Resizing(target_h, target_w, interpolation='bilinear')(skip1)\n",
    "\n",
    "  # Concatenate x and skip1 - they should now have the same spatial dimensions (64, 64)\n",
    "  x = layers.Concatenate()([x, skip1])\n",
    "\n",
    "  # Decoder path\n",
    "  x = layers.Conv2D(256, 3, padding='same', use_bias=False,\n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda))(x) # Added regularization\n",
    "  x = layers.BatchNormalization()(x)\n",
    "  x = layers.Activation('relu')(x)\n",
    "\n",
    "  x = layers.Conv2D(256, 3, padding='same', use_bias=False,\n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda))(x) # Added regularization\n",
    "  x = layers.BatchNormalization()(x)\n",
    "  x = layers.Activation('relu')(x)\n",
    "\n",
    "  # Final Upsampling to the original input size (256, 256)\n",
    "  # Ensure the upsampling factor is calculated correctly based on the current size of x\n",
    "  x = layers.UpSampling2D(size=(input_shape[0] // x.shape[1], input_shape[1] // x.shape[2]), interpolation='bilinear')(x)\n",
    "\n",
    "\n",
    "  output = layers.Conv2D(n_classes, 1, padding='same', activation='softmax')(x)\n",
    "  return Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r9M2W3Zh-3i4"
   },
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model(\"deeplabv3plus_urinary_cells.h5\", custom_objects={'dice_loss': dice_loss, 'combined_focal_dice': combined_focal_dice})\n",
    "model = DeepLabV3Plus(l2_lambda=0.0001) # You can experiment with different lambda values\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "  initial_learning_rate,\n",
    "  decay_steps=100000,\n",
    "  decay_rate=0.9,\n",
    "  staircase=True\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "class_weights = [1, 20, 5, 15, 10, 1, 5, 15]\n",
    "\n",
    "model.compile(\n",
    "      optimizer=optimizer,\n",
    "      loss=\"categorical_crossentropy\",\n",
    "      #loss=combined_loss(class_weights, gamma=2.0, weight_dice=1.0),\n",
    "      metrics=[MeanIoU(num_classes=8), dice_coefficient]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S_D-aZuMIxeq",
    "outputId": "9221fa4e-5559-4c54-c7bd-dbe0b2af085f"
   },
   "outputs": [],
   "source": [
    "# # Add a callback to print the learning rate per epoch\n",
    "# class LearningRateLogger(tf.keras.callbacks.Callback):\n",
    "#     def __init__(self, lr_schedule):\n",
    "#         super().__init__()\n",
    "#         self.lr_schedule = lr_schedule # Store the scheduler object\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         # Call the scheduler object with the current step (optimizer.iterations)\n",
    "#         lr = self.lr_schedule(self.model.optimizer.iterations).numpy()\n",
    "#         print(f\"Epoch {epoch + 1}: Learning Rate = {lr:.6f}\")\n",
    "\n",
    "# # Define an Early Stopping callback\n",
    "# early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "#     monitor='val_mean_io_u_3', # Monitor the validation mean IoU\n",
    "#     patience=10,           # Number of epochs with no improvement after which training will be stopped.\n",
    "#     mode='max',            # Stop when the monitored quantity has maximized\n",
    "#     restore_best_weights=True # Restore model weights from the epoch with the best value of the monitored quantity.\n",
    "# )\n",
    "\n",
    "# # Instantiate the LearningRateLogger with the actual lr_schedule object\n",
    "# lr_logger = LearningRateLogger(lr_schedule)\n",
    "\n",
    "\n",
    "# Train the model with the Early Stopping and Learning Rate Logger callbacks\n",
    "history = model.fit( # Capture the training history\n",
    "  train_dataset,\n",
    "  validation_data=validation_dataset,\n",
    "  epochs=100, # Set a relatively large number of epochs\n",
    ")\n",
    "\n",
    "# # Plot training and validation loss and IoU\n",
    "# plt.figure(figsize=(12, 6))\n",
    "\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(history.history['loss'], label='Training Loss')\n",
    "# plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "# plt.title('Loss over Epochs')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(history.history['mean_io_u_3'], label='Training Mean IoU')\n",
    "# plt.plot(history.history['val_mean_io_u_3'], label='Validation Mean IoU')\n",
    "# plt.title('Mean IoU over Epochs')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Mean IoU')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "-2XarmqFNKwr",
    "outputId": "e48d2018-ce18-450d-f4be-69d8e8c3530c"
   },
   "outputs": [],
   "source": [
    "# model.save(\"deeplabv3plus.keras\")\n",
    "\n",
    "\n",
    "results = model.evaluate(test_dataset)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "_-7OnDKzTJHZ",
    "outputId": "f70570e4-025a-4912-d3f3-250ee35cdced"
   },
   "outputs": [],
   "source": [
    "# Salvare model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(18,5)) # Increased figure size to accommodate more plots\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(history.history['mean_io_u_3'], label='Train Mean IoU') # Use the metric name added in compile\n",
    "plt.plot(history.history['val_mean_io_u_3'], label='Validation Mean IoU') # Use the metric name added in compile\n",
    "plt.title('Mean IoU')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(history.history['dice_coefficient'], label='Train Dice') # Use the metric name added in compile\n",
    "plt.plot(history.history['val_dice_coefficient'], label='Validation Dice') # Use the metric name added in compile\n",
    "plt.title('Dice Coefficient')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HDLF-NXgUM_q",
    "outputId": "30041de5-084e-4492-a4ae-5939fcea8669"
   },
   "outputs": [],
   "source": [
    "def calculate_dice_per_class(model, dataset, num_classes=8, smooth=1e-6):\n",
    "  intersection = np.zeros(num_classes)\n",
    "  union = np.zeros(num_classes)\n",
    "\n",
    "  for img_batch, mask_batch in dataset:\n",
    "    preds = model.predict(img_batch)\n",
    "    preds = np.argmax(preds, axis=-1)\n",
    "    masks = np.argmax(mask_batch.numpy(), axis=-1)\n",
    "\n",
    "    for cls in range(num_classes):\n",
    "      pred_cls = (preds == cls).astype(np.float32)\n",
    "      mask_cls = (masks == cls).astype(np.float32)\n",
    "\n",
    "      intersection[cls] += np.sum(pred_cls * mask_cls)\n",
    "      union[cls] += np.sum(pred_cls) + np.sum(mask_cls)\n",
    "\n",
    "  dice_per_class = (2. * intersection + smooth) / (union + smooth)\n",
    "\n",
    "  print(\"=== Dice Score per clasă ===\")\n",
    "  for i, score in enumerate(dice_per_class):\n",
    "    print(f\"Clasă {i}: {score:.4f}\")\n",
    "\n",
    "  return dice_per_class\n",
    "\n",
    "# Apelează funcția\n",
    "dice_scores = calculate_dice_per_class(model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zkyT1t_OUjrg",
    "outputId": "cc9e6cbd-e656-439f-b262-9709facb610d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Culori RGB pentru cele 8 clase\n",
    "clase_culori = np.array([\n",
    "    [0, 0, 0],       # 0 - Background\n",
    "    [255, 0, 0],     # 1 - Rod\n",
    "    [0, 255, 0],     # 2 - RBC/WBC\n",
    "    [0, 0, 255],     # 3 - Yeast\n",
    "    [255, 255, 0],   # 4 - Misc\n",
    "    [255, 0, 255],   # 5 - Single EPC\n",
    "    [0, 255, 255],   # 6 - Small EPC sheet\n",
    "    [255, 165, 0]    # 7 - Large EPC sheet\n",
    "], dtype=np.uint8)\n",
    "\n",
    "def decode_mask(mask_one_hot):\n",
    "  mask_labels = np.argmax(mask_one_hot, axis=-1)\n",
    "  return clase_culori[mask_labels]\n",
    "\n",
    "def vizualizeaza_predictii(model, dataset, nume_dataset=\"Test Set\", nume_model=\"Model\", nume_pred=\"Predicție\", n=5):\n",
    "  fig, axes = plt.subplots(n, 3, figsize=(15, 5 * n))\n",
    "  for i, (img_batch, mask_batch) in enumerate(dataset.take(n)):\n",
    "    img = img_batch[0].numpy()\n",
    "    mask_true = mask_batch[0].numpy()\n",
    "\n",
    "    pred = model.predict(np.expand_dims(img, axis=0))[0]\n",
    "    img_display = ((img + 1) / 2).squeeze()\n",
    "\n",
    "    mask_true_rgb = decode_mask(mask_true)\n",
    "    mask_pred_rgb = decode_mask(pred)\n",
    "\n",
    "    axes[i, 0].imshow(img_display, cmap='gray')\n",
    "    axes[i, 0].set_title(f\"{nume_dataset} - Imagine {i+1}\")\n",
    "    axes[i, 0].axis('off')\n",
    "\n",
    "    axes[i, 1].imshow(mask_true_rgb)\n",
    "    axes[i, 1].set_title(\"Ground Truth\")\n",
    "    axes[i, 1].axis('off')\n",
    "\n",
    "    axes[i, 2].imshow(mask_pred_rgb)\n",
    "    axes[i, 2].set_title(nume_pred)\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "# Apelează funcția\n",
    "vizualizeaza_predictii(model, test_dataset, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-aY5R-7ofUJN"
   },
   "source": [
    "# Fine Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Voea1vuwexio",
    "outputId": "32025553-ef98-42e6-addb-510d97d59c61"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "num_classes = 8\n",
    "\n",
    "# Colectăm toate valorile\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "for img_batch, mask_batch in test_dataset:\n",
    "  pred_batch = model.predict(img_batch)\n",
    "  y_pred = tf.argmax(pred_batch, axis=-1).numpy().flatten()\n",
    "  y_true = tf.argmax(mask_batch, axis=-1).numpy().flatten()\n",
    "  y_pred_all.extend(y_pred)\n",
    "  y_true_all.extend(y_true)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_mat = confusion_matrix(y_true_all, y_pred_all, labels=list(range(num_classes)))\n",
    "\n",
    "# Calcul IoU pe fiecare clasă\n",
    "ious = []\n",
    "for i in range(num_classes):\n",
    "  tp = conf_mat[i, i]\n",
    "  fn = np.sum(conf_mat[i, :]) - tp\n",
    "  fp = np.sum(conf_mat[:, i]) - tp\n",
    "  denom = tp + fp + fn\n",
    "  iou = tp / denom if denom != 0 else 0.0\n",
    "  ious.append(iou)\n",
    "\n",
    "# Afișare\n",
    "for i, iou in enumerate(ious):\n",
    "  print(f\"Clasa {i}: IoU = {iou:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "-aY5R-7ofUJN"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
